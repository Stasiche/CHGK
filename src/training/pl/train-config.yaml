tokenizer: "sberbank-ai/rugpt3small_based_on_gpt2"
model: "sberbank-ai/rugpt3small_based_on_gpt2"
seed: 65537

dataset:
  path: "data/questions.txt"
  train_size: 0.85
  train_batch_size: 8
  val_batch_size: 8


training:
  n_gpus: 1
  output_dir: "training_output/"
  save_model_dir: "training_output/model/"

  opt:
    lr: 2e-5
    w_decay: 0.01
    max_epochs: 1
    warmup_steps: 10000
    grad_accumulation_steps: 1
    grad_clip: 1

  logging:
    val_check_interval: 0.05
    save_top_k: 2
    log_steps: 100

hydra:
  run:
    dir: training_output_data/${now:%Y-%m-%d}/${now:%H-%M-%S}
output:
  logger_dir: training_output_data/